---
sidebar_label: 2.0.0 Release Notes
sidebar_position: 1
title: "Version 2.0.0 Release Notes"
description: Release notes for CrestApps.OrchardCore 2.0.0 — new modules, breaking changes, and migration guide.
---

# Version 2.0.0 Release Notes

**Package version**: `2.0.0-preview-0001`

This is a major release that introduces new modules, an orchestrator-based architecture, Omnichannel Communications, expanded MCP protocol support, and document handling capabilities.

---

## New Modules

### AI Chat Interactions

- **Feature ID**: `CrestApps.OrchardCore.AI.Chat.Interactions`
- Provides ad-hoc chat sessions with configurable parameters — users can adjust model settings, attach documents, upload images, and generate charts without requiring a predefined AI profile.

### AI Chat Copilot Integration

- **Feature ID**: `CrestApps.OrchardCore.AI.Chat.Copilot`
- Integrates with the GitHub Copilot SDK to provide a Copilot-based orchestrator for AI completions.

### AI Documents

A suite of modules for document upload, text extraction, and embedding during chat sessions:

| Module | Feature ID |
|--------|------------|
| AI Documents (Core) | `CrestApps.OrchardCore.AI.Documents` |
| PDF Support | `CrestApps.OrchardCore.AI.Documents.Pdf` |
| OpenXml Support (Word, Excel, PowerPoint) | `CrestApps.OrchardCore.AI.Documents.OpenXml` |
| Azure AI Search | `CrestApps.OrchardCore.AI.Documents.AzureAI` |
| Elasticsearch | `CrestApps.OrchardCore.AI.Documents.Elasticsearch` |

### AI Data Sources

Modules for RAG (Retrieval-Augmented Generation) and knowledge base indexing:

| Module | Feature ID |
|--------|------------|
| AI Data Sources (Core) | `CrestApps.OrchardCore.AI.DataSources` |
| Azure AI Search | `CrestApps.OrchardCore.AI.DataSources.AzureAI` |
| Elasticsearch | `CrestApps.OrchardCore.AI.DataSources.Elasticsearch` |

### MCP Resource Adapters

| Module | Feature ID |
|--------|------------|
| FTP Resources | `CrestApps.OrchardCore.AI.Mcp.Resources.Ftp` |
| SFTP Resources | `CrestApps.OrchardCore.AI.Mcp.Resources.Sftp` |

### Omnichannel Communications

A new suite of modules for multi-channel communication:

| Module | Feature ID | Description |
|--------|------------|-------------|
| Omnichannel (Core) | `CrestApps.OrchardCore.Omnichannel` | Core omnichannel services |
| SMS | `CrestApps.OrchardCore.Omnichannel.Sms` | AI-driven SMS automation with Twilio |
| Event Grid | `CrestApps.OrchardCore.Omnichannel.EventGrid` | Azure Event Grid webhook integration |
| Management | `CrestApps.OrchardCore.Omnichannel.Managements` | Contact and conversation management |

### Recipes Module

- **Feature ID**: `CrestApps.OrchardCore.Recipes`
- Provides recipe steps for configuring CrestApps modules via recipes.

---

## New Features in Existing Modules

### AI Services (`CrestApps.OrchardCore.AI`)

- **Orchestrator Architecture** — The new `IOrchestrator` interface replaces the previous prompt routing system. The orchestrator manages planning, tool scoping, and iterative agent execution loops.
- **AI Tool Registration** — New fluent API for registering AI tools with `.AddAITool<T>()`, supporting categories, purposes, and selectable/system tool modes.
- **AI Profile Types** — Added `Utility` and `TemplatePrompt` profile types in addition to `Chat`.
- **AI Deployments** — New feature for managing AI model deployments.
- **AI Connection Management** — UI for managing provider connections from the admin dashboard.
- **AI Chat WebAPI** — RESTful API endpoints for interacting with AI chat.
- **Workflow Integration** — AI Completion tasks for Orchard Core Workflows.

### MCP (`CrestApps.OrchardCore.AI.Mcp`)

- **MCP Server** — Expose your Orchard Core site as an MCP server endpoint, allowing external AI agents to discover and use your tools, prompts, and resources.
- **MCP Prompts and Resources** — Prompts and resources can be added and managed via the admin UI.
- **Templated Resources** — Support for dynamic MCP resources defined with URI templates.
- **Stdio Transport** — Connect to local MCP servers (e.g., Docker containers) via Standard Input/Output.

### AI Agent (`CrestApps.OrchardCore.AI.Agent`)

- Expanded toolset with 30+ built-in tools covering content management, tenant management, feature toggles, workflow automation, and communication tasks.

---

## Improvements

### Unified Citation & Reference System

The citation and reference system has been completely reworked so that **every AI provider** (Azure OpenAI, OpenAI, Ollama, Azure AI Inference) now returns the same citation references. Previously, citations only worked with Azure OpenAI's native data-sources feature (`GetMessageContext()`); since we now inject context ourselves via preemptive RAG and tool-based search, that approach no longer applied.

**What changed:**

- **`[doc:N]` citation markers** are now produced consistently by both Data Source and Document preemptive RAG handlers, as well as by the `DataSourceSearchTool` and `SearchDocumentsTool` AI tools.
- **`referenceType`** is stored in the knowledge base index so the system knows whether a reference is a Content item, an uploaded Document, or a custom data source type.
- **`AICompletionReference`** now includes `ReferenceId` and `ReferenceType` properties, enabling downstream consumers (hubs, UI) to generate appropriate links.
- **`IAIReferenceLinkResolver`** — a new keyed-service interface for resolving reference links by type. Register custom resolvers with `services.AddKeyedScoped<IAIReferenceLinkResolver, MyResolver>("MyType")` to generate links for custom reference types.
- **`CompositeAIReferenceLinkResolver`** dispatches to the correct keyed resolver based on `referenceType`. When no resolver is registered, the reference is shown without a link.
- **`CitationReferenceCollector`** collects references from all sources (preemptive RAG context, tool-invoked searches) and resolves links in a single pass.
- **Content item link resolution** — `DefaultAILinkGenerator` is registered as a keyed `IAIReferenceLinkResolver` for the `"Content"` reference type. Content item references automatically receive links generated via OrchardCore's `LinkGenerator` with the standard `OrchardCore.Contents` route. Document references (uploaded files) are shown by filename without a link.
- **`DocumentChunkSearchResult`** now includes `DocumentKey` and `FileName` properties for uploaded document citation tracking.
- **Azure OpenAI**: Removed the deprecated `GetMessageContext()` / `Citations` extraction logic and the `IAILinkGenerator` dependency from `AzureOpenAICompletionClient`. References are now handled uniformly via the orchestration pipeline.
- **`AIInvocationScope` / `AIInvocationContext`** — new `AsyncLocal<T>`-based ambient context that replaces `HttpContext.Items` for all per-invocation AI data. This ensures full isolation between concurrent SignalR hub calls on the same WebSocket connection, preventing reference leaks, stale data source IDs, and other cross-invocation contamination issues. See the [AI Tools documentation](../ai/ai-tools.md#invocation-context-aiinvocationscope) for details.
- **Shared reference counter** — `AIInvocationContext.NextReferenceIndex()` provides a monotonically increasing, thread-safe counter used by all preemptive RAG handlers and search tools, ensuring `[doc:N]` indices never collide even when data source and document references are produced in the same request.
- **Incremental citation delivery** — Citation references are now collected and sent to the client progressively during streaming. Preemptive RAG references (from data sources and documents) are resolved before the streaming loop starts, so the first chunk already includes them. Tool-invoked references are merged incrementally during streaming as tools execute. This ensures the JavaScript client can render `[doc:N]` superscripts in real-time.
- **`ChatSession` moved to `Items` dictionary** — `AIInvocationContext.ChatSession` property has been removed. The chat session is now stored in `AIInvocationContext.Items["AIChatSession"]` instead. Tools that need the chat session should read from `Items` (e.g., `invocationContext.Items.TryGetValue("AIChatSession", out var session)`).
- **IsInScope evaluation moved to orchestrator** — The `IsInScope` constraint is no longer evaluated by individual preemptive RAG handlers (`DataSourcePreemptiveRagHandler`, `DocumentPreemptiveRagHandler`). Instead, the `PreemptiveRagOrchestrationHandler` evaluates it after all handlers have run. When no references are produced across all sources and `IsInScope` is enabled, a scoping directive is injected. When tools are available, the directive encourages the model to try tool-based search before concluding no answer exists, allowing `search_data_source` and `search_documents` to discover relevant content that the initial preemptive search missed.
- **Tool-search instructions when preemptive RAG is disabled** — When preemptive RAG is disabled but data sources or documents are attached, the orchestrator now injects system-message instructions guiding the model to call search tools (`search_data_source`, `search_documents`) to retrieve internal knowledge. When `IsInScope` is enabled, the model is forced to use only tool-retrieved content and must refuse to answer from general knowledge. When `IsInScope` is disabled, the model is instructed to try the search tools first and may supplement with general knowledge only if no relevant results are found.
- **RAG text normalization** — Content and titles are now normalized before chunking and embedding using `RagTextNormalizer`. HTML tags, Markdown formatting, escaped HTML entities, and extraneous whitespace are stripped to produce clean plain text. This improves embedding quality, reduces token usage when injecting context into prompts, and prevents raw HTML from leaking into reference titles and chat UI. Normalization uses [`Microsoft.Extensions.DataIngestion.Markdig`](https://www.nuget.org/packages/Microsoft.Extensions.DataIngestion.Markdig) for structured Markdown-to-plain-text conversion, combined with HTML tag stripping and entity decoding. Titles in citation references are also normalized at creation time as a defense-in-depth measure for existing indexed data.
- **Token-aware chunking** — The custom character-based text chunking has been replaced with `DocumentTokenChunker` from [`Microsoft.Extensions.DataIngestion`](https://www.nuget.org/packages/Microsoft.Extensions.DataIngestion). This uses actual LLM tokenizers (GPT-4o `o200k_base`) to split content at token boundaries with configurable overlap, producing chunks that align better with embedding model token limits.
- **`IngestionDocumentReader`-based document parsing** — The custom `IDocumentTextExtractor` interface has been replaced with [`Microsoft.Extensions.DataIngestion.IngestionDocumentReader`](https://learn.microsoft.com/dotnet/api/microsoft.extensions.dataingestion.ingestiondocumentreader), the standard abstraction from `Microsoft.Extensions.DataIngestion`. Each document module now provides an `IngestionDocumentReader` implementation registered as a keyed singleton by file extension. The built-in `MarkdownReader` from `Microsoft.Extensions.DataIngestion.Markdig` is used for Markdown files. Custom PDF and OpenXml readers extend `IngestionDocumentReader` following the same patterns used in Microsoft's AI templates. Use `services.AddIngestionDocumentReader<T>(extensions)` to register custom readers — this replaces the previous `AddDocumentTextExtractor<T>()` method.
- **Inline citation markers** — The system prompt now instructs the AI model to include `[doc:N]` reference markers inline in its response text, immediately after the relevant statement. This enables users to see which statements are sourced from which references.
- **Context-gated system tools** — The `search_data_sources` and document processing tools (`search_documents`, `list_documents`, `read_document`, `read_tabular_data`) are now conditionally included in the tool registry based on context availability. `search_data_sources` is only available when a data source is attached to the AI profile or chat interaction. Document processing tools are only available when documents are attached to the session. This prevents the AI model from seeing tools it cannot use, eliminating hallucinated tool calls and reducing token overhead. The `SystemToolRegistryProvider` checks `AICompletionContext.DataSourceId` for data sources and `AICompletionContextKeys.HasDocuments` in `AdditionalProperties` for documents.

**Breaking:** If you relied on `chunk.AdditionalProperties["ContentItemIds"]` or `chunk.AdditionalProperties["References"]` being set on streaming chunks by the Azure OpenAI provider, these are no longer set on individual chunks. References are now collected progressively during streaming from the orchestration context and tool execution context.

**Breaking:** If you wrote custom AI tools that read `AIToolExecutionContext` from `HttpContext.Items[nameof(AIToolExecutionContext)]`, update them to use `AIInvocationScope.Current?.ToolExecutionContext` instead. Similarly, if you read `HttpContext.Items["DataSourceId"]` or `HttpContext.Items["ToolSearchReferences"]`, these are now on `AIInvocationScope.Current.DataSourceId` and `AIInvocationScope.Current.ToolReferences` respectively.

**Breaking:** If you accessed `AIInvocationContext.ChatSession`, use `AIInvocationScope.Current?.Items["AIChatSession"]` instead.

**Breaking:** The `IDocumentTextExtractor` interface has been removed. If you implemented a custom document text extractor, migrate it to an `IngestionDocumentReader` subclass and register it with `services.AddIngestionDocumentReader<T>(extensions)` instead of `AddDocumentTextExtractor<T>(extensions)`. The reader's `ReadAsync` method returns an `IngestionDocument` instead of a raw string — the document processing service extracts text from the `IngestionDocument` automatically.

**Note:** Data sources and documents indexed before this release may contain raw HTML or Markdown in their content and titles. To benefit from normalization, re-index your data sources after upgrading.

---

## Breaking Changes

### Changed: Navigation Paths

Orchard Core v3 removed the **Configuration** tab. Update any documentation or code that references:

- `Configuration → Features` → Use **Tools → Features**
- `Configuration → Settings` → Use **Settings** directly

### Changed: Package Version Scheme

Package versions now use the `2.0.0-preview-XXXX` scheme instead of `2.0.0-beta-XXXX`.

---

## Migration Guide from v1.x

### Step 1: Update Package References

Update all CrestApps package references to `2.0.0-preview-0001` or later:

```xml
<PackageReference Include="CrestApps.OrchardCore.Cms.Core.Targets" Version="2.0.0-preview-0001" />
```

### Step 2: Remove Prompt Routing Code

If you used `AddPromptProcessingIntent`, `IPromptIntentDetector`, or `IPromptProcessingStrategy`, remove these references. The orchestrator now handles all request processing automatically.

### Step 3: Update Tool Registrations

If you registered custom AI tools, update to the new fluent API:

```csharp
// Old (v1.x)
// services.AddSingleton<AIFunction, MyTool>();

// New (v2.0)
services.AddAITool<MyTool>(MyTool.TheName)
    .WithTitle("My Tool")
    .WithDescription("Description for the orchestrator")
    .Selectable();
```

### Step 4: Enable New Features

New modules are not enabled by default. Enable them via **Tools → Features** in the admin dashboard as needed.
