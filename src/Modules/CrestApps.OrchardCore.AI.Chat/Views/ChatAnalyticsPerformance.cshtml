@model CrestApps.OrchardCore.AI.Chat.ViewModels.ChatAnalyticsPerformanceViewModel

<div class="card mb-3">
    <div class="card-header">
        <h5 class="card-title mb-0">
            <i class="fa-solid fa-gauge-high me-1"></i>@T["Model & System Performance"]
            <i class="fa-solid fa-circle-info ms-1 small" data-bs-toggle="tooltip" title="@T["Metrics about the AI model's response speed and resource consumption. These metrics are captured when the AI provider returns token usage and latency data."]"></i>
        </h5>
    </div>
    <div class="card-body">
        @if (Model.HasData)
        {
            <div class="row text-center">
                <div class="col-md-3 mb-3">
                    <div class="border rounded p-3">
                        <div class="fs-2 fw-bold text-primary">@FormatLatency(Model.AverageResponseLatencyMs)</div>
                        <div class="text-muted">
                            @T["Avg Response Latency"]
                            <i class="fa-solid fa-circle-info ms-1" data-bs-toggle="tooltip" title="@T["The average time (in milliseconds) the AI model takes to generate a complete response. Lower latency means faster responses for users. Based on {0} sessions.", Model.SessionsWithLatencyData]"></i>
                        </div>
                    </div>
                </div>
                <div class="col-md-3 mb-3">
                    <div class="border rounded p-3">
                        <div class="fs-2 fw-bold text-info">@FormatTokenCount(Model.TotalTokens)</div>
                        <div class="text-muted">
                            @T["Total Tokens Used"]
                            <i class="fa-solid fa-circle-info ms-1" data-bs-toggle="tooltip" title="@T["The total number of tokens (input + output) consumed across all sessions. Tokens are the basic units of text that AI models process, and token usage directly affects API costs."]"></i>
                        </div>
                    </div>
                </div>
                <div class="col-md-3 mb-3">
                    <div class="border rounded p-3">
                        <div class="fs-2 fw-bold text-success">@FormatTokenCount(Model.TotalInputTokens)</div>
                        <div class="text-muted">
                            @T["Input Tokens"]
                            <i class="fa-solid fa-circle-info ms-1" data-bs-toggle="tooltip" title="@T["The total number of input (prompt) tokens sent to the AI model. This includes the conversation history, system instructions, and user messages."]"></i>
                        </div>
                    </div>
                </div>
                <div class="col-md-3 mb-3">
                    <div class="border rounded p-3">
                        <div class="fs-2 fw-bold text-warning">@FormatTokenCount(Model.TotalOutputTokens)</div>
                        <div class="text-muted">
                            @T["Output Tokens"]
                            <i class="fa-solid fa-circle-info ms-1" data-bs-toggle="tooltip" title="@T["The total number of output (completion) tokens generated by the AI model. These are the tokens in the assistant's responses."]"></i>
                        </div>
                    </div>
                </div>
            </div>
            <div class="row text-center">
                <div class="col-md-4 mb-3">
                    <div class="border rounded p-3">
                        <div class="fs-3 fw-bold">@Model.AverageTokensPerSession</div>
                        <div class="text-muted">
                            @T["Avg Tokens/Session"]
                            <i class="fa-solid fa-circle-info ms-1" data-bs-toggle="tooltip" title="@T["The average total tokens consumed per session. Useful for estimating per-conversation costs and monitoring usage efficiency."]"></i>
                        </div>
                    </div>
                </div>
                <div class="col-md-4 mb-3">
                    <div class="border rounded p-3">
                        <div class="fs-3 fw-bold">@Model.AverageInputTokensPerSession</div>
                        <div class="text-muted">
                            @T["Avg Input Tokens/Session"]
                            <i class="fa-solid fa-circle-info ms-1" data-bs-toggle="tooltip" title="@T["The average input tokens per session. High values may indicate lengthy conversation histories or verbose system prompts."]"></i>
                        </div>
                    </div>
                </div>
                <div class="col-md-4 mb-3">
                    <div class="border rounded p-3">
                        <div class="fs-3 fw-bold">@Model.AverageOutputTokensPerSession</div>
                        <div class="text-muted">
                            @T["Avg Output Tokens/Session"]
                            <i class="fa-solid fa-circle-info ms-1" data-bs-toggle="tooltip" title="@T["The average output tokens per session. Indicates how verbose the AI responses are on average."]"></i>
                        </div>
                    </div>
                </div>
            </div>
        }
        else
        {
            <p class="text-muted mb-0">@T["No performance data available. Performance metrics are captured when the AI provider returns token usage and latency information."]</p>
        }
    </div>
</div>

@functions {
    string FormatLatency(double ms)
    {
        if (ms < 1000)
        {
            return $"{ms:F0}ms";
        }

        var seconds = ms / 1000;
        return $"{seconds:F1}s";
    }

    string FormatTokenCount(long tokens)
    {
        if (tokens < 1000)
        {
            return tokens.ToString();
        }

        if (tokens < 1_000_000)
        {
            return $"{tokens / 1000.0:F1}K";
        }

        return $"{tokens / 1_000_000.0:F2}M";
    }
}
